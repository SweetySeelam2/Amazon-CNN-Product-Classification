import streamlit as st 
import numpy as np
import os
import requests
import json
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from lime import lime_image
from skimage.segmentation import mark_boundaries

# === CONFIG ===
MODEL_PATH = "cnn_baseline_final_v2.keras"
MODEL_RELEASE_URL = "https://huggingface.co/spaces/sweetyseelam/Amazon-CNN-Product-Classification-v2/resolve/main/cnn_baseline_final_v2.keras"
SAMPLE_IMAGES_DIR = "sample_images"
LABEL_JSON = "index_to_label.json"
LABEL_JSON_URL = "https://raw.githubusercontent.com/SweetySeelam2/Amazon-CNN-Product-Classification/main/index_to_label.json"
IMG_SIZE = (224, 224)
MAX_SAMPLE_IMAGES = 100  # Limit dropdown to 100 for speed

def download_if_missing(local_path, url, is_binary=False):
    if not os.path.exists(local_path):
        with st.spinner(f"Downloading {os.path.basename(local_path)} ..."):
            r = requests.get(url, stream=is_binary)
            if r.status_code == 200:
                mode = "wb" if is_binary else "w"
                with open(local_path, mode) as f:
                    if is_binary:
                        for chunk in r.iter_content(chunk_size=8192):
                            f.write(chunk)
                    else:
                        f.write(r.text)
                st.success(f"‚úÖ Downloaded {os.path.basename(local_path)}.")
            else:
                st.error(f"‚ùå Failed to download {os.path.basename(local_path)} from {url}")
                st.stop()

# --- Download/check files ---
download_if_missing(MODEL_PATH, MODEL_RELEASE_URL, is_binary=True)
download_if_missing(LABEL_JSON, LABEL_JSON_URL)

# --- Load model and label mapping ---
model = load_model(MODEL_PATH)
with open(LABEL_JSON, "r") as f:
    index_to_label = json.load(f)

# --- Multi-page navigation ---
st.set_page_config(page_title="üß† Amazon Product Classifier", layout="wide")
PAGES = {
    "üè† Introduction": "intro",
    "üîç Classifier & LIME Explanation": "predict",
    "üìä Results, Impact & Storytelling": "results"
}
page = st.sidebar.radio("Go to:", list(PAGES.keys()))

def footer():
    st.markdown("---")
    st.markdown(
        """
        <p style='text-align: center; font-size: 12px;'>
        ¬© 2025 <strong>Sweety Seelam</strong>. All rights reserved. <br>
        Model and code protected under copyright. Reuse without permission is prohibited.
        </p>
        """,
        unsafe_allow_html=True
    )

# --- PAGE 1: Introduction ---
if PAGES[page] == "intro":
    st.title("üß† Amazon Product Image Classifier with LIME")
    st.markdown("""
    Welcome to a state-of-the-art **Explainable AI app** that classifies fashion product images and visually explains its decisions with LIME!  
    ---
    **Project Overview:**
    - Classifies fashion product images (e.g., boots, shoes, shirts, bags, heels) using a high-accuracy CNN model.
    - Explains every prediction with a **LIME heatmap** so business users can *trust* and *understand* the AI.
    - Built for e-commerce catalog managers, product teams, data scientists, and anyone needing transparency and automation.

    **Business Problem:**
    - Manual product tagging is slow, inconsistent, and lacks transparency.
    - Retailers like Amazon, Walmart, Flipkart, Target, and Shopify need fast, explainable automation.

    **Our Solution:**
    - Upload any product image or choose from 100+ real samples.
    - Instantly get a predicted category and an interactive visual explanation.
    - Confidence scores for transparency and auditability.
    - Easy to use ‚Äî no coding required.

    *Ready to see it in action? Click "Classifier & LIME Explanation" in the sidebar to start!*  
    """)
    footer()

# --- PAGE 2: Classifier + LIME (main app) ---
if PAGES[page] == "predict":
    st.title("üîç Product Classifier & LIME Visual Explanation")
    st.markdown("Upload a product image **or** select a sample image below to get a prediction and see *why* the AI made its decision.")

    # Sample images (first 100)
    try:
        sample_files = [
            f for f in sorted(os.listdir(SAMPLE_IMAGES_DIR))
            if f.lower().endswith((".jpg", ".jpeg", ".png"))
        ][:MAX_SAMPLE_IMAGES]
    except Exception as e:
        sample_files = []
        st.warning(f"Could not find or read sample_images: {e}")

    uploaded_file = st.file_uploader("üì§ Upload a product image", type=["jpg", "jpeg", "png"])
    st.markdown("### OR")
    selected_sample = st.selectbox("Select a sample image from the project:", ["None"] + sample_files)

    img_path = None
    true_label = None

    if uploaded_file:
        img_path = "uploaded_image.jpg"
        with open(img_path, "wb") as f:
            f.write(uploaded_file.read())
        show_true_label = False
    elif selected_sample != "None" and selected_sample in sample_files:
        img_path = os.path.join(SAMPLE_IMAGES_DIR, selected_sample)
        fname = os.path.splitext(selected_sample)[0]
        if fname.isdigit() and fname in index_to_label:
            true_label = index_to_label[fname]
        else:
            true_label = "Unknown"
        show_true_label = True
    else:
        st.info("Upload a product image **or** select a sample image above to begin.")
        footer()
        st.stop()

    # Preprocess image
    img = image.load_img(img_path, target_size=IMG_SIZE)
    img_array = image.img_to_array(img) / 255.0
    img_input = np.expand_dims(img_array, axis=0)

    # Prediction
    pred = model.predict(img_input)
    pred_idx = int(np.argmax(pred))
    pred_label = index_to_label[str(pred_idx)]
    confidence = round(100 * np.max(pred), 2)

    # Results
    st.image(img_path, caption="Input Image", width=300)
    st.markdown(f"‚úÖ <b>Predicted Label:</b> <span style='color:#388e3c'>{pred_label}</span>", unsafe_allow_html=True)
    st.markdown(f"üìä <b>Confidence Score:</b> <span style='color:#1565c0'>{confidence}%</span>", unsafe_allow_html=True)
    if show_true_label:
        st.markdown(f"üéØ <b>True Label:</b> <span style='color:#ba0c2f'>{true_label}</span>", unsafe_allow_html=True)

    # LIME Explanation
    st.markdown("## üîç LIME Visual Explanation")
    with st.spinner("Generating LIME explanation..."):
        explainer = lime_image.LimeImageExplainer()
        explanation = explainer.explain_instance(
            img_array.astype('double'),
            classifier_fn=lambda x: model.predict(x),
            top_labels=1,
            hide_color=0,
            num_samples=1000
        )
        temp, mask = explanation.get_image_and_mask(
            pred_idx,
            positive_only=True,
            num_features=5,
            hide_rest=False
        )
        fig, ax = plt.subplots()
        ax.imshow(mark_boundaries(temp / 255.0, mask))
        ax.axis("off")
        st.pyplot(fig)
        lime_filename = f"LIME_Explanation_{pred_label}_img.png"
        fig.savefig(lime_filename, bbox_inches='tight')
        with open(lime_filename, "rb") as f:
            st.download_button("üì• Download LIME Heatmap", f, file_name=lime_filename)

    # LIME interpretation block
    st.markdown(
        """
        <div style="background-color: #f0f2f6; padding: 1em; border-radius: 8px; margin-top: 1.5em;">
        <b>How to interpret this LIME output?</b><br><br>
        <b>LIME</b> (Local Interpretable Model-agnostic Explanations) is an explainable AI tool that shows <b>which image regions most influenced the model‚Äôs decision</b>.<br>
        <ul>
          <li>The yellow-highlighted areas are <b>most important</b> for the predicted class.</li>
          <li>For example, if classifying 'Tshirt', yellow regions may cover the neckline or shirt print.</li>
          <li>This helps business users verify the model is looking at the <b>right features</b> and not being biased or random.</li>
        </ul>
        <b>Why does this matter?</b>
        <ul>
          <li>Builds trust for product teams, managers, and auditors</li>
          <li>Makes model decisions <b>transparent, auditable, and compliant</b> with business/regulatory needs</li>
          <li>Accelerates onboarding and model adoption in e-commerce & retail</li>
        </ul>
        <b>Business impact:</b>
        <ul>
          <li>High-value predictions with human-interpretable explanations empower smarter automation</li>
        </ul>
        </div>
        """, unsafe_allow_html=True
    )

    # --- NEW: Per-image conclusion, business impact, and recommendation blocks ---
    st.markdown("### üìà Conclusion & Business Impact")
    st.info(
        f"""
        <b>Conclusion:</b> This image was classified as <b>{pred_label}</b> with a high confidence of <b>{confidence}%</b>.
        <br>
        <b>Business Impact:</b> Automating the identification of this product type can save up to <b>$1.25</b> per image in manual costs, scale to thousands of listings, and deliver fast, accurate, auditable cataloging ‚Äî improving efficiency for retailers like Amazon, Walmart, Flipkart, and Shopify.
        """, unsafe_allow_html=True
    )

    st.markdown("### üíº Business Recommendations")
    st.success(
        f"""
        <ul>
        <li>Adopt automated classification for product images to cut costs and reduce errors.</li>
        <li>Use LIME explanations to build trust with catalog, audit, and merchandising teams ‚Äî ensure the AI focuses on the correct visual features for <b>{pred_label}</b>-type products.</li>
        <li>Enable rapid onboarding for new products and categories with transparent, explainable AI ‚Äî this will support better search, compliance, and customer experience at scale.</li>
        </ul>
        """, unsafe_allow_html=True
    )

    footer()

# --- PAGE 3: Results/Analysis/Storytelling ---
if PAGES[page] == "results":
    st.title("üìä Results, Analysis, Business Impact & Storytelling")
    st.markdown("""
    **Model Results & Interpretation**
    - Trained on a curated fashion dataset of 550 images, using a balanced and professional CNN pipeline.
    - Achieved **91.6% classification accuracy** (test set), with typical confidence scores of 95‚Äì100% on clean samples.
    - LIME heatmaps consistently highlight the correct visual regions (e.g., shoe sole, heel, shirt print).

    **Business Impact & ROI**
    | Metric                   | Value Estimate          |
    |--------------------------|------------------------|
    | üí≤ Manual Tagging Cost   | ~$1.25 per image       |
    | üìà Images per Year       | ~100,000+ (retailers)  |
    | üíµ Cost Savings          | ~$125,000+ per year    |
    | ‚è±Ô∏è Time Saved/Image      | ~45 seconds            |
    | üìä Consistency           | 100% auditable         |

    **Business Recommendations**
    - If adopted by Amazon, Walmart, Myntra, Shein, Nykaa, Flipkart, Target, etc.:
      - Reduce human labor costs and inconsistencies
      - Increase onboarding speed for new SKUs
      - Provide more accurate, explainable catalog search
      - Enable audit-readiness and trust for compliance

    **Project Storytelling**
    Imagine a retailer like Amazon onboarding thousands of new products every month. Instead of slow, error-prone manual tagging, this system:
    - Instantly classifies each new image
    - Justifies its answer visually
    - Saves over **$125,000/year** and enables 100% transparent automation
    - Empowers merchandisers and data teams with full model trust and accountability

    This app is a leap forward for explainable AI in retail ‚Äî and a model for scalable, ethical automation.
    """)
    footer()